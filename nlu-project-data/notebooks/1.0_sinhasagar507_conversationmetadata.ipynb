{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "42bb0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from typing import List\n",
    "    from pandas import DataFrame\n",
    "    import seaborn as sns\n",
    "    from tqdm import tqdm\n",
    "    from time import time\n",
    "    from convokit import Corpus, download\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8120e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(\"sanskar_transformed_corpora/tr_fc(12-23)_27p_1\") # Load the modified corpora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "49aab4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_df = corpus.get_utterances_dataframe().drop(\"vectors\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "fa9b0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_metadata_agg = {} # Create a conversation-level dictionary \n",
    "utt_df = corpus.get_utterances_dataframe().drop(\"vectors\", axis = 1) # Load the utterance dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a6dd16fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 581.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 853 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "utt_df[\"negative_polarity\"] = \"None\"\n",
    "utt_df[\"positive_polarity\"] = \"None\"\n",
    "utt_df[\"neutral_polarity\"] = \"None\"\n",
    "utt_df[\"gratitude\"] = \"None\"\n",
    "utt_df[\"deference\"] = \"None\"\n",
    "utt_df[\"greeting\"] = \"None\"\n",
    "utt_df[\"positive_lexicon\"] = \"None\"\n",
    "utt_df[\"apologizing\"] = \"None\"\n",
    "utt_df[\"please\"] = \"None\"\n",
    "\n",
    "\n",
    "for idx in tqdm(utt_df.index):\n",
    "    utt_df.loc[idx, \"negative_polarity\"] = utt_df.loc[idx, \"meta.sentiment_polarity\"][\"neg\"]\n",
    "    utt_df.loc[idx, \"positive_polarity\"] = utt_df.loc[idx, \"meta.sentiment_polarity\"][\"pos\"]\n",
    "    utt_df.loc[idx, \"neutral_polarity\"]  = utt_df.loc[idx, \"meta.sentiment_polarity\"][\"neu\"]\n",
    "    utt_df.loc[idx, \"gratitude\"]         = utt_df.loc[idx, \"meta.politeness_markers\"][\"feature_politeness_==Gratitude==\"]\n",
    "    utt_df.loc[idx, \"deference\"]         = utt_df.loc[idx, \"meta.politeness_markers\"][\"feature_politeness_==Deference==\"]\n",
    "    utt_df.loc[idx, \"greeting\"]          = utt_df.loc[idx, \"meta.politeness_markers\"][\"feature_politeness_==Indirect_(greeting)==\"]\n",
    "    utt_df.loc[idx, \"positive_lexicon\"]  = utt_df.loc[idx, \"meta.politeness_markers\"][\"feature_politeness_==HASPOSITIVE==\"]\n",
    "    utt_df.loc[idx, \"apologizing\"]       = utt_df.loc[idx, \"meta.politeness_markers\"][\"feature_politeness_==Apologizing==\"]\n",
    "    utt_df.loc[idx, \"please\"]            = utt_df.loc[idx, \"meta.politeness_markers\"][\"feature_politeness_==Please==\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "de46110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_df[\"negative_polarity\"] = utt_df[\"meta.sentiment_polarity\"].apply(lambda val_dict: val_dict[\"neg\"])\n",
    "utt_df\"positive_polarity\"] = utt_df[\"meta.positive_polarity\"].apply(lambda val_dict: val_dict[\"pos\"])\n",
    "utt_df[\"neutral_polarity\"] = utt_df[\"meta.neutral_polarity\"].apply(lambda val_dict: val_dict[\"neu\"])\n",
    "utt_df[\"gratitude\"] = utt_df.loc[\"meta.politeness_markers\"].apply(lambda val_dict: val_dict[\"feature_politeness_==Gratitude==\"]\n",
    "utt_df[\"deference\"] = utt_df.loc[\"meta.politeness_markers\"].apply(lambda val_dict: val_dict[\"feature_politeness_==Deference==\"]\n",
    "utt_df[\"greeting\"] = utt_df.loc[idx, \"meta.politeness_markers\"].apply(lambda val_dict: val_dict[\"feature_politeness_==Indirect_(greeting)==\"]                                                             \n",
    "utt_df[\"positive_lexicon\"]  = utt_df[\"meta.politeness_markers\"].apply(lambda val_dict: val_dict[\"feature_politeness_==HASPOSITIVE==\"])\n",
    "utt_df[\"apologizing\"]       = utt_df[\"meta.politeness_markers\"].apply(lambda val_dict: val_dict[\"feature_politeness_==Apologizing==\"])\n",
    "utt_df[\"please\"]            = utt_df[\"meta.politeness_markers\"].apply(lambda val_dict: val_dict[\"feature_politeness_==Please==\"])                                                              \n",
    "utt_df[\"subjectivity_score\"] = utt_df[\"meta.subjectivity_score\"].apply(lambda val_dict: val_dict[\"avg_subjectivity_score\"])\n",
    "utt_df[\"subjectivity_clue_count\"] = utt_df[\"meta.subjectivity_score\"].apply(lambda val_dict: val_dict[\"subjective_lexicon_count\"])\n",
    "utt_df[\"modifier_count\"] = utt_df[\"meta.modifier_count\"].apply(lambda val_dict: val_dict[\"count_mod_tags\"])\n",
    "utt_df[\"hedge_count\"] = utt_df[\"meta.hedge_count\"].apply(lambda val_dict: val_dict[\"count_hedges\"])\n",
    "utt_df[\"groupRef_count\"] = utt_df[\"meta.groupRef_count\"].apply(lambda val_dict: val_dict[\"count_group_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b50d21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_df_grouped = utt_df.groupby(by = \"conversation_id\", as_index = True).agg({\"hedge_count\": [\"mean\"], \"groupRef_count\": [\"mean\"], \"subjectivity_clue_count\": [\"mean\"], \"modifier_count\": [\"mean\"], \"subjectivity_score\": [\"mean\"], \"negative_polarity\": [\"mean\"], \"positive_polarity\": [\"mean\"], \"neutral_polarity\": [\"mean\"], \"gratitude\": [\"sum\"], \"deference\": [\"sum\"], \"greeting\": [\"sum\"], \"positive_lexicon\": [\"sum\"], \"apologizing\": [\"sum\"], \"please\": [\"sum\"], \"meta.insult\": [\"sum\"], \"meta.identity_attack\": [\"sum\"], \"meta.toxicity\": [\"mean\"], \"meta.severe_toxicity\": [\"mean\"],\"meta.profanity\": [\"mean\"]})\n",
    "utt_df_grouped = utt_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "bc8ccfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:00, 416.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(utt_df_grouped.iterrows()):\n",
    "    conv_id = str(row[\"conversation_id\"].values[0])\n",
    "    conv_metadata_agg[conv_id] = {}\n",
    "    conv_metadata_agg[conv_id][\"hedge_count\"] = row[\"hedge_count\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"groupRef_count\"] = row[\"groupRef_count\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"subjectivity_clue_count\"] = row[\"subjectivity_clue_count\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"subjectivity_score\"] = round(row[\"subjectivity_score\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"negative_polarity\"] = round(row[\"negative_polarity\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"positive_polarity\"] = round(row[\"positive_polarity\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"neutral_polarity\"] = round(row[\"neutral_polarity\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"gratitude\"] = row[\"gratitude\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"deference\"] = row[\"deference\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"greeting\"] = round(row[\"greeting\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"positive_lexicon\"] = row[\"positive_lexicon\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"please\"] = row[\"please\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"apologizing\"] = row[\"apologizing\"].values[0]\n",
    "    conv_metadata_agg[conv_id][\"insult\"] = round(row[\"meta.insult\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"identity_attack\"] = round(row[\"meta.identity_attack\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"toxicity\"] = round(row[\"meta.toxicity\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"severe_toxicity\"] = round(row[\"meta.severe_toxicity\"].values[0], 3)\n",
    "    conv_metadata_agg[conv_id][\"profanity\"] = round(row[\"meta.profanity\"].values[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1e2d688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 13886.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for conv_id in tqdm(corpus.get_conversation_ids()):\n",
    "    convo = corpus.get_conversation(conv_id)\n",
    "    convo.add_meta(\"hedge_count\", conv_metadata_agg[conv_id][\"hedge_count\"])\n",
    "    convo.add_meta(\"groupRef_count\", conv_metadata_agg[conv_id][\"groupRef_count\"])\n",
    "    convo.add_meta(\"subjectivity_clue_count\", conv_metadata_agg[conv_id][\"subjectivity_clue_count\"])\n",
    "    convo.add_meta(\"subjectivity_score\", conv_metadata_agg[conv_id][\"subjectivity_score\"])\n",
    "    convo.add_meta(\"negative_polarity\", conv_metadata_agg[conv_id][\"negative_polarity\"])\n",
    "    convo.add_meta(\"positive_polarity\", conv_metadata_agg[conv_id][\"positive_polarity\"])\n",
    "    convo.add_meta(\"neutral_polarity\", conv_metadata_agg[conv_id][\"neutral_polarity\"])\n",
    "    convo.add_meta(\"gratitude\", conv_metadata_agg[conv_id][\"gratitude\"])\n",
    "    convo.add_meta(\"deference\", conv_metadata_agg[conv_id][\"deference\"])\n",
    "    convo.add_meta(\"greeting\", conv_metadata_agg[conv_id][\"greeting\"])\n",
    "    convo.add_meta(\"positive_lexicon\", conv_metadata_agg[conv_id][\"positive_lexicon\"])\n",
    "    convo.add_meta(\"apologizing\", conv_metadata_agg[conv_id][\"apologizing\"])\n",
    "    convo.add_meta(\"please\", conv_metadata_agg[conv_id][\"please\"])\n",
    "    convo.add_meta(\"insult\", conv_metadata_agg[conv_id][\"insult\"])\n",
    "    convo.add_meta(\"identity_attack\", conv_metadata_agg[conv_id][\"identity_attack\"])\n",
    "    convo.add_meta(\"toxicity\", conv_metadata_agg[conv_id][\"toxicity\"])\n",
    "    convo.add_meta(\"severe_toxicity\", conv_metadata_agg[conv_id][\"severe_toxicity\"])\n",
    "    convo.add_meta(\"profanity\", conv_metadata_agg[conv_id][\"profanity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3d8a4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store final dataframe to corpus \n",
    "CORPUS_NAME = \"tr_fc(12-23)_27p_1\"\n",
    "BASE_PATH = \"C:\\Sagar Study\\ML and Learning\\CP Sem-8\\Data\\Reddit\\saved-corpora\\sanskar_transformed_corpora\"\n",
    "corpus.dump(CORPUS_NAME, base_path=BASE_PATH)    # Dump corpus and load "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
